BERT_MODEL_NAME: bert-base-multilingual-cased
batch_size: 8
cache_dir: ./cache_dir
data_dir: ./data/kfold
early_max_stopping: 6
epochs: 20
hidden_dim: 256
learning_rate: 0.0001
model: bert_lstm
model_name: model_checkpoint_concat_bert_lstm
model_save_dir: ./saved_model_dir
n_layers: 1
output_dim: 2
train_type: concat
visualize: false
weight_decay: 1.0e-06
